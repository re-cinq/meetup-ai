apiVersion: scaffolder.backstage.io/v1beta3
kind: Template
metadata:
  name: chatbot-k8s
  title: Chatbot Application
  description: Deploy a Large Language Model (LLM)-enabled chat application directly to Kubernetes.
  tags: ["ai", "llamacpp", "vllm", "python", "kubernetes"]
  annotations:
    backstage.io/techdocs-ref: dir:.
spec:
  type: service
  parameters:
    - title: Application Information
      required:
        - name
        - owner
        - modelServer
      properties:
        name:
          title: Name
          type: string
          description: Unique name of the component
          ui:autofocus: true
          ui:options:
            rows: 5
          maxLength: 63
        owner:
          title: Owner
          type: string
          description: Owner of the component
          default: user:guest
        modelServer:
          title: Model Server
          description: |
            llama.cpp: A Python binding of LLM inference in C/C++ with minimal setup. | [Learn more](https://github.com/containers/ai-lab-recipes/tree/main/model_servers/llamacpp_python)

            vLLM: A high throughput, memory efficient inference and serving engine with GPU support for LLMs. If you choose vLLM, ensure that your cluster has Nvidia GPU nodes available (with compute capability 7.0 or higher). | [Learn more](https://github.com/vllm-project/vllm)
          default: llama.cpp
          type: string
          enum:
            - vLLM
            - llama.cpp
            - Existing model server
      dependencies:
        modelServer:
          oneOf:
            - required:
                - modelEndpoint
                - modelName
              properties:
                modelServer:
                  const: Existing model server
                modelEndpoint:
                  title: Model Server Endpoint
                  type: string
                  description: "The endpoint for an existing model server."
                modelName:
                  title: Model Name
                  type: string
                  ui:help: "The name of the model deployed on the model server you would like to use."
            - properties:
                modelServer:
                  const: vLLM
                modelNameDeployed:
                  title: Model Name
                  description: Text Generation | Apache-2.0 | [Learn more](https://huggingface.co/instructlab/granite-7b-lab)
                  default: instructlab/granite-7b-lab
                  type: string
                  enum:
                    - instructlab/granite-7b-lab
            - properties:
                modelServer:
                  const: llama.cpp
                modelNameDeployed:
                  title: Model Name
                  description: Text Generation | Apache-2.0 | [Learn more](https://huggingface.co/instructlab/granite-7b-lab)
                  default: instructlab/granite-7b-lab
                  type: string
                  enum:
                    - instructlab/granite-7b-lab
    - title: Kubernetes Deployment Information
      required:
        - namespace
      properties:
        namespace:
          title: Deployment Namespace
          type: string
          default: ai-apps
          ui:autofocus: true
  steps:
    - id: fetch-base
      name: Fetch Base
      action: fetch:template
      input:
        url: ./content
        targetPath: ./
        values:
          name: ${{ parameters.name }}
          namespace: ${{ parameters.namespace }}
          modelServer: ${{ parameters.modelServer }}
          modelName: ${{ parameters.modelName if parameters.modelServer === 'Existing model server' else parameters.modelNameDeployed }}
          owner: ${{ parameters.owner }}
          appPort: 8501
          modelServicePort: 8001
          vllmSelected: ${{ parameters.modelServer === 'vLLM' }}
          existingModelServer: ${{ parameters.modelServer === 'Existing model server' }}
          modelEndpoint: ${{ parameters.modelEndpoint }}

  output:
    links:
      - title: Deployment Instructions
        url: ./README.md